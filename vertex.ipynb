{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Vertex AI\n",
    "\n",
    "To configure the environment copy your Google Cloud JSON file with credentials into ./env/gcp.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwriting `from langchain_google_vertexai import VertexAI` to ensure that `with telemetry.tool_context_manager(llm._user_agent):` is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, AsyncIterator, Dict, Iterator, List, Optional, Union\n",
    "\n",
    "from google.cloud.aiplatform import telemetry\n",
    "from langchain_core.callbacks.manager import (\n",
    "    AsyncCallbackManagerForLLMRun,\n",
    "    CallbackManagerForLLMRun,\n",
    ")\n",
    "from langchain_core.language_models.llms import BaseLLM\n",
    "from langchain_core.outputs import Generation, GenerationChunk, LLMResult\n",
    "from langchain_core.pydantic_v1 import root_validator\n",
    "from vertexai.generative_models import (  # type: ignore[import-untyped]\n",
    "    Candidate,\n",
    "    GenerativeModel,\n",
    "    Image,\n",
    ")\n",
    "from vertexai.language_models import (  # type: ignore[import-untyped]\n",
    "    CodeGenerationModel,\n",
    "    TextGenerationModel,\n",
    ")\n",
    "from vertexai.language_models._language_models import (  # type: ignore[import-untyped]\n",
    "    TextGenerationResponse,\n",
    ")\n",
    "from vertexai.preview.language_models import (  # type: ignore[import-untyped]\n",
    "    CodeGenerationModel as PreviewCodeGenerationModel,\n",
    ")\n",
    "from vertexai.preview.language_models import (\n",
    "    TextGenerationModel as PreviewTextGenerationModel,\n",
    ")\n",
    "\n",
    "from langchain_google_vertexai._base import (\n",
    "    _VertexAICommon,\n",
    ")\n",
    "from langchain_google_vertexai._utils import (\n",
    "    create_retry_decorator,\n",
    "    get_generation_info,\n",
    "    is_codey_model,\n",
    "    is_gemini_model,\n",
    ")\n",
    "\n",
    "\n",
    "def _completion_with_retry(\n",
    "    llm: VertexAI,\n",
    "    prompt: List[Union[str, Image]],\n",
    "    stream: bool = False,\n",
    "    is_gemini: bool = False,\n",
    "    run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "    **kwargs: Any,\n",
    ") -> Any:\n",
    "    \"\"\"Use tenacity to retry the completion call.\"\"\"\n",
    "    retry_decorator = create_retry_decorator(\n",
    "        max_retries=llm.max_retries, run_manager=run_manager\n",
    "    )\n",
    "\n",
    "    @retry_decorator\n",
    "    def _completion_with_retry_inner(\n",
    "        prompt: List[Union[str, Image]], is_gemini: bool = False, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        if is_gemini:\n",
    "            return llm.client.generate_content(\n",
    "                prompt,\n",
    "                stream=stream,\n",
    "                safety_settings=kwargs.pop(\"safety_settings\", None),\n",
    "                generation_config=kwargs,\n",
    "            )\n",
    "        else:\n",
    "            if stream:\n",
    "                return llm.client.predict_streaming(prompt[0], **kwargs)\n",
    "            return llm.client.predict(prompt[0], **kwargs)\n",
    "\n",
    "    with telemetry.tool_context_manager(llm._user_agent):\n",
    "        return _completion_with_retry_inner(prompt, is_gemini, **kwargs)\n",
    "\n",
    "\n",
    "async def _acompletion_with_retry(\n",
    "    llm: VertexAI,\n",
    "    prompt: str,\n",
    "    is_gemini: bool = False,\n",
    "    stream: bool = False,\n",
    "    run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "    **kwargs: Any,\n",
    ") -> Any:\n",
    "    \"\"\"Use tenacity to retry the completion call.\"\"\"\n",
    "    retry_decorator = create_retry_decorator(\n",
    "        max_retries=llm.max_retries, run_manager=run_manager\n",
    "    )\n",
    "\n",
    "    @retry_decorator\n",
    "    async def _acompletion_with_retry_inner(\n",
    "        prompt: str, is_gemini: bool = False, stream: bool = False, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        if is_gemini:\n",
    "            return await llm.client.generate_content_async(\n",
    "                prompt,\n",
    "                generation_config=kwargs,\n",
    "                stream=stream,\n",
    "                safety_settings=kwargs.pop(\"safety_settings\", None),\n",
    "            )\n",
    "        if stream:\n",
    "            raise ValueError(\"Async streaming is supported only for Gemini family!\")\n",
    "        return await llm.client.predict_async(prompt, **kwargs)\n",
    "\n",
    "    # with telemetry.tool_context_manager(llm._user_agent):\n",
    "    return await _acompletion_with_retry_inner(\n",
    "        prompt, is_gemini, stream=stream, **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "class VertexAI(_VertexAICommon, BaseLLM):\n",
    "    \"\"\"Google Vertex AI large language models.\"\"\"\n",
    "\n",
    "    model_name: str = \"text-bison\"\n",
    "    \"The name of the Vertex AI large language model.\"\n",
    "    tuned_model_name: Optional[str] = None\n",
    "    \"The name of a tuned model. If provided, model_name is ignored.\"\n",
    "\n",
    "    @classmethod\n",
    "    def is_lc_serializable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @classmethod\n",
    "    def get_lc_namespace(cls) -> List[str]:\n",
    "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
    "        return [\"langchain\", \"llms\", \"vertexai\"]\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
    "        tuned_model_name = values.get(\"tuned_model_name\")\n",
    "        model_name = values[\"model_name\"]\n",
    "        safety_settings = values[\"safety_settings\"]\n",
    "        is_gemini = is_gemini_model(values[\"model_name\"])\n",
    "        cls._init_vertexai(values)\n",
    "\n",
    "        if safety_settings and (not is_gemini or tuned_model_name):\n",
    "            raise ValueError(\"Safety settings are only supported for Gemini models\")\n",
    "\n",
    "        if is_codey_model(model_name):\n",
    "            model_cls = CodeGenerationModel\n",
    "            preview_model_cls = PreviewCodeGenerationModel\n",
    "        elif is_gemini:\n",
    "            model_cls = GenerativeModel\n",
    "            preview_model_cls = GenerativeModel\n",
    "        else:\n",
    "            model_cls = TextGenerationModel\n",
    "            preview_model_cls = PreviewTextGenerationModel\n",
    "\n",
    "        if tuned_model_name:\n",
    "            values[\"client\"] = model_cls.get_tuned_model(tuned_model_name)\n",
    "            values[\"client_preview\"] = preview_model_cls.get_tuned_model(\n",
    "                tuned_model_name\n",
    "            )\n",
    "        else:\n",
    "            if is_gemini:\n",
    "                values[\"client\"] = model_cls(\n",
    "                    model_name=model_name, safety_settings=safety_settings\n",
    "                )\n",
    "                values[\"client_preview\"] = preview_model_cls(\n",
    "                    model_name=model_name, safety_settings=safety_settings\n",
    "                )\n",
    "            else:\n",
    "                values[\"client\"] = model_cls.from_pretrained(model_name)\n",
    "                values[\"client_preview\"] = preview_model_cls.from_pretrained(model_name)\n",
    "\n",
    "        if values[\"streaming\"] and values[\"n\"] > 1:\n",
    "            raise ValueError(\"Only one candidate can be generated with streaming!\")\n",
    "        return values\n",
    "\n",
    "    def _candidate_to_generation(\n",
    "        self,\n",
    "        response: Union[Candidate, TextGenerationResponse],\n",
    "        *,\n",
    "        stream: bool = False,\n",
    "        usage_metadata: Optional[Dict] = None,\n",
    "    ) -> GenerationChunk:\n",
    "        \"\"\"Converts a stream response to a generation chunk.\"\"\"\n",
    "        generation_info = get_generation_info(\n",
    "            response,\n",
    "            self._is_gemini_model,\n",
    "            stream=stream,\n",
    "            usage_metadata=usage_metadata,\n",
    "        )\n",
    "        generation_info[\"model_name\"] = self.model_name\n",
    "        try:\n",
    "            text = response.text\n",
    "        except AttributeError:\n",
    "            text = \"\"\n",
    "        except ValueError:\n",
    "            text = \"\"\n",
    "        return GenerationChunk(\n",
    "            text=text,\n",
    "            generation_info=generation_info,\n",
    "        )\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        should_stream = stream if stream is not None else self.streaming\n",
    "        params = self._prepare_params(stop=stop, stream=should_stream, **kwargs)\n",
    "        generations: List[List[Generation]] = []\n",
    "        for prompt in prompts:\n",
    "            if should_stream:\n",
    "                generation = GenerationChunk(text=\"\")\n",
    "                for chunk in self._stream(\n",
    "                    prompt, stop=stop, run_manager=run_manager, **kwargs\n",
    "                ):\n",
    "                    generation += chunk\n",
    "                generations.append([generation])\n",
    "            else:\n",
    "                res = _completion_with_retry(\n",
    "                    self,\n",
    "                    [prompt],\n",
    "                    stream=should_stream,\n",
    "                    is_gemini=self._is_gemini_model,\n",
    "                    run_manager=run_manager,\n",
    "                    **params,\n",
    "                )\n",
    "                if self._is_gemini_model:\n",
    "                    usage_metadata = res.to_dict().get(\"usage_metadata\")\n",
    "                else:\n",
    "                    usage_metadata = res.raw_prediction_response.metadata\n",
    "                generations.append(\n",
    "                    [\n",
    "                        self._candidate_to_generation(r, usage_metadata=usage_metadata)\n",
    "                        for r in res.candidates\n",
    "                    ]\n",
    "                )\n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    async def _agenerate(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> LLMResult:\n",
    "        params = self._prepare_params(stop=stop, **kwargs)\n",
    "        generations: List[List[Generation]] = []\n",
    "        for prompt in prompts:\n",
    "            res = await _acompletion_with_retry(\n",
    "                self,\n",
    "                prompt,\n",
    "                is_gemini=self._is_gemini_model,\n",
    "                run_manager=run_manager,\n",
    "                **params,\n",
    "            )\n",
    "            if self._is_gemini_model:\n",
    "                usage_metadata = res.to_dict().get(\"usage_metadata\")\n",
    "            else:\n",
    "                usage_metadata = res.raw_prediction_response.metadata\n",
    "            generations.append(\n",
    "                [\n",
    "                    self._candidate_to_generation(r, usage_metadata=usage_metadata)\n",
    "                    for r in res.candidates\n",
    "                ]\n",
    "            )\n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[GenerationChunk]:\n",
    "        params = self._prepare_params(stop=stop, stream=True, **kwargs)\n",
    "        for stream_resp in _completion_with_retry(\n",
    "            self,\n",
    "            [prompt],\n",
    "            stream=True,\n",
    "            is_gemini=self._is_gemini_model,\n",
    "            run_manager=run_manager,\n",
    "            **params,\n",
    "        ):\n",
    "            usage_metadata = None\n",
    "            if self._is_gemini_model:\n",
    "                usage_metadata = stream_resp.to_dict().get(\"usage_metadata\")\n",
    "                stream_resp = stream_resp.candidates[0]\n",
    "            chunk = self._candidate_to_generation(\n",
    "                stream_resp, stream=True, usage_metadata=usage_metadata\n",
    "            )\n",
    "            yield chunk\n",
    "            if run_manager:\n",
    "                run_manager.on_llm_new_token(\n",
    "                    chunk.text,\n",
    "                    chunk=chunk,\n",
    "                    verbose=self.verbose,\n",
    "                )\n",
    "\n",
    "    async def _astream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterator[GenerationChunk]:\n",
    "        params = self._prepare_params(stop=stop, stream=True, **kwargs)\n",
    "        if not self._is_gemini_model:\n",
    "            raise ValueError(\"Async streaming is supported only for Gemini family!\")\n",
    "        async for chunk in await _acompletion_with_retry(\n",
    "            self,\n",
    "            prompt,\n",
    "            stream=True,\n",
    "            is_gemini=self._is_gemini_model,\n",
    "            run_manager=run_manager,\n",
    "            **params,\n",
    "        ):\n",
    "            usage_metadata = chunk.to_dict().get(\"usage_metadata\")\n",
    "            chunk = self._candidate_to_generation(\n",
    "                chunk.candidates[0], stream=True, usage_metadata=usage_metadata\n",
    "            )\n",
    "            yield chunk\n",
    "            if run_manager:\n",
    "                await run_manager.on_llm_new_token(\n",
    "                    chunk.text, chunk=chunk, verbose=self.verbose\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "import vertexai\n",
    "\n",
    "langchain.debug = True\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./env/gcp.json\"\n",
    "vertexai.init()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Please translate the following text into the Italian language.\n",
    "\n",
    "Payment will be charged to your Apple ID account at the confirmation of purchase. Subscription automatically renews unless it is canceled at least 24 hours before the end of the current period. Your account will be charged for renewal within 24 hours prior to the end of the current period. You can manage and cancel your subscriptions by going to your account settings on the App Store after purchase. Any unused portion of a free trial period, if offered, will be forfeited when the user purchases a subscription to that publication, where applicable\n",
    "\"\"\"\n",
    "models = [\n",
    "    {\n",
    "        \"model\": \"gemini-1.5-pro-preview-0409\",\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 1,\n",
    "    },\n",
    "    {\"model\": \"gemini-1.0-pro\", \"temperature\": 0.8, \"top_p\": 1},\n",
    "    {\"model\": \"text-bison-32k\", \"temperature\": 0.8, \"top_p\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:VertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Please translate the following text into the Italian language.\\n\\nPayment will be charged to your Apple ID account at the confirmation of purchase. Subscription automatically renews unless it is canceled at least 24 hours before the end of the current period. Your account will be charged for renewal within 24 hours prior to the end of the current period. You can manage and cancel your subscriptions by going to your account settings on the App Store after purchase. Any unused portion of a free trial period, if offered, will be forfeited when the user purchases a subscription to that publication, where applicable\"\n",
      "  ]\n",
      "}\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:VertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Please translate the following text into the Italian language.\\n\\nPayment will be charged to your Apple ID account at the confirmation of purchase. Subscription automatically renews unless it is canceled at least 24 hours before the end of the current period. Your account will be charged for renewal within 24 hours prior to the end of the current period. You can manage and cancel your subscriptions by going to your account settings on the App Store after purchase. Any unused portion of a free trial period, if offered, will be forfeited when the user purchases a subscription to that publication, where applicable\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:VertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Please translate the following text into the Italian language.\\n\\nPayment will be charged to your Apple ID account at the confirmation of purchase. Subscription automatically renews unless it is canceled at least 24 hours before the end of the current period. Your account will be charged for renewal within 24 hours prior to the end of the current period. You can manage and cancel your subscriptions by going to your account settings on the App Store after purchase. Any unused portion of a free trial period, if offered, will be forfeited when the user purchases a subscription to that publication, where applicable\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:VertexAI] [2.41s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": {\n",
      "            \"citations\": [\n",
      "              {\n",
      "                \"start_index\": 45,\n",
      "                \"end_index\": 168,\n",
      "                \"uri\": \"https://apps.apple.com/ch/app/forza-football-live-scores/id500138120?l=it\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 100,\n",
      "                \"end_index\": 221,\n",
      "                \"uri\": \"https://play.google.com/store/apps/details?id=com.studio.obe&hl=it&gl=US\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 465,\n",
      "                \"end_index\": 596,\n",
      "                \"uri\": \"https://apps.apple.com/it/app/unisci-collage-cornici-di-foto/id1509008174\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 496,\n",
      "                \"end_index\": 632,\n",
      "                \"uri\": \"https://play.google.com/store/apps/details?id=com.americangreetings.ecards&hl=it&gl=US\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 118,\n",
      "            \"total_token_count\": 118\n",
      "          },\n",
      "          \"model_name\": \"gemini-1.0-pro\"\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:VertexAI] [2.92s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Il pagamento verrà addebitato sul tuo account Apple ID alla conferma dell'acquisto. L'abbonamento si rinnova automaticamente, a meno che non venga annullato almeno 24 ore prima della fine del periodo corrente. L'importo del rinnovo verrà addebitato sul tuo account entro 24 ore dalla fine del periodo corrente. Puoi gestire e annullare i tuoi abbonamenti accedendo alle impostazioni dell'account sull'App Store dopo l'acquisto. L'eventuale parte inutilizzata di un periodo di prova gratuito, se offerto, verrà annullata quando l'utente\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"errors\": [],\n",
      "          \"safety_attributes\": [\n",
      "            {\n",
      "              \"Derogatory\": 0.1,\n",
      "              \"Finance\": 0.9,\n",
      "              \"Health\": 0.2,\n",
      "              \"Insult\": 0.1,\n",
      "              \"Legal\": 0.1,\n",
      "              \"Religion & Belief\": 0.2,\n",
      "              \"Sexual\": 0.1,\n",
      "              \"Toxic\": 0.1,\n",
      "              \"War & Conflict\": 0.1\n",
      "            }\n",
      "          ],\n",
      "          \"grounding_metadata\": {\n",
      "            \"citations\": [],\n",
      "            \"search_queries\": []\n",
      "          },\n",
      "          \"usage_metadata\": {\n",
      "            \"candidates_billable_characters\": 459.0,\n",
      "            \"candidates_token_count\": 128.0,\n",
      "            \"prompt_billable_characters\": 514.0,\n",
      "            \"prompt_token_count\": 118.0\n",
      "          },\n",
      "          \"model_name\": \"text-bison-32k\"\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:VertexAI] [4.77s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": {\n",
      "            \"citations\": [\n",
      "              {\n",
      "                \"end_index\": 170,\n",
      "                \"uri\": \"https://apps.apple.com/it/app/alarmy-sveglia-mattutina/id1163786766\",\n",
      "                \"start_index\": 0,\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 191,\n",
      "                \"end_index\": 351,\n",
      "                \"uri\": \"https://apps.apple.com/it/app/direct-mail/id500040344?mt=12\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 241,\n",
      "                \"end_index\": 396,\n",
      "                \"uri\": \"https://apps.apple.com/it/app/convertitore-di-valuta-valute/id1457309557\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              },\n",
      "              {\n",
      "                \"start_index\": 428,\n",
      "                \"end_index\": 578,\n",
      "                \"uri\": \"https://play.google.com/store/apps/details?id=com.endel.endel&hl=it\",\n",
      "                \"title\": \"\",\n",
      "                \"license_\": \"\"\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 118,\n",
      "            \"total_token_count\": 118\n",
      "          },\n",
      "          \"model_name\": \"gemini-1.5-pro-preview-0409\"\n",
      "        },\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "['', '', \" Il pagamento verrà addebitato sul tuo account Apple ID alla conferma dell'acquisto. L'abbonamento si rinnova automaticamente, a meno che non venga annullato almeno 24 ore prima della fine del periodo corrente. L'importo del rinnovo verrà addebitato sul tuo account entro 24 ore dalla fine del periodo corrente. Puoi gestire e annullare i tuoi abbonamenti accedendo alle impostazioni dell'account sull'App Store dopo l'acquisto. L'eventuale parte inutilizzata di un periodo di prova gratuito, se offerto, verrà annullata quando l'utente\"]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "## Uncomment the following line to use the VertexAI language model\n",
    "## This will lead to parallelization errors like \n",
    "## .venv/lib/python3.11/site-packages/google/cloud/aiplatform/telemetry.py\\\", line 57, in _pop_tool_name\n",
    "##    raise RuntimeError(\\n\\n\\nRuntimeError: Tool context error detected. This can occur due to parallelization.\"\n",
    "\n",
    "# from langchain_google_vertexai import VertexAI\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for model in models:\n",
    "    llm = VertexAI(\n",
    "        model_name=model[\"model\"],\n",
    "        temperature=model[\"temperature\"],\n",
    "        top_p=model[\"top_p\"],\n",
    "        tags=[model[\"model\"]],\n",
    "    )\n",
    "    tasks.append(llm.ainvoke(prompt))\n",
    "\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Il pagamento verrà addebitato sul tuo account ID Apple alla conferma dell\\'acquisto. L\\'abbonamento si rinnova automaticamente a meno che non venga annullato almeno 24 ore prima della fine del periodo corrente. Il tuo account verrà addebitato per il rinnovo entro 24 ore prima della fine del periodo corrente. Puoi gestire e annullare i tuoi abbonamenti accedendo alle impostazioni del tuo account sull\\'App Store dopo l\\'acquisto. Qualsiasi porzione inutilizzata di un periodo di prova gratuito, se offerto, verrà annullata quando l\\'utente acquista un abbonamento a tale pubblicazione, ove applicabile. \\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0690379292\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0941766649\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.145600617\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.114368536\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.158695191\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.129953817\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.10951516\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0970475525\n",
      "  }\n",
      "  citation_metadata {\n",
      "    citations {\n",
      "      end_index: 170\n",
      "      uri: \"https://apps.apple.com/it/app/alarmy-sveglia-mattutina/id1163786766\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 191\n",
      "      end_index: 351\n",
      "      uri: \"https://apps.apple.com/it/app/direct-mail/id500040344?mt=12\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 241\n",
      "      end_index: 396\n",
      "      uri: \"https://apps.apple.com/it/app/convertitore-di-valuta-valute/id1457309557\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 411\n",
      "      end_index: 559\n",
      "      uri: \"https://apps.apple.com/it/app/brass-icone-widget/id1533158013\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 118\n",
      "  candidates_token_count: 140\n",
      "  total_token_count: 258\n",
      "}\n",
      "\n",
      "candidates {\n",
      "  finish_reason: RECITATION\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.067546688\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0977343246\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.138228953\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.103567153\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.143667594\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.115162224\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.10141132\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0809367076\n",
      "  }\n",
      "  citation_metadata {\n",
      "    citations {\n",
      "      start_index: 17\n",
      "      end_index: 140\n",
      "      uri: \"https://apps.apple.com/ch/app/forza-football-live-scores/id500138120?l=it\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 110\n",
      "      end_index: 308\n",
      "      uri: \"https://apps.apple.com/it/app/brushes-for-procreate/id1507750565\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 320\n",
      "      end_index: 495\n",
      "      uri: \"https://play.google.com/store/apps/details?id=app.brooog.strongikev2&hl=it&gl=US\"\n",
      "    }\n",
      "    citations {\n",
      "      start_index: 417\n",
      "      end_index: 597\n",
      "      uri: \"https://apps.apple.com/it/app/impara-linglese-con-lingualeo/id480952151\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 118\n",
      "  total_token_count: 118\n",
      "}\n",
      "\n",
      "Error processing prompt: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: text-bison-32k. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "\n",
    "async def generate_completion(model, prompt):\n",
    "    try:\n",
    "        model = GenerativeModel(\n",
    "            model_name=model[\"model\"],\n",
    "            generation_config={\n",
    "                \"temperature\": model[\"temperature\"],\n",
    "                \"top_p\": model[\"top_p\"],\n",
    "            },\n",
    "        )\n",
    "        response = await model.generate_content_async(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error processing prompt: {e}\"\n",
    "\n",
    "\n",
    "tasks = [generate_completion(model, prompt) for model in models]\n",
    "results = await asyncio.gather(*tasks)\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
